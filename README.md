# nextdoor-scraper

This project extracts **company names**, **emails**, and **websites (if available)** from 100 business pages on [Nextdoor.com](https://nextdoor.com). The scraped data is saved into an Excel file.

## ğŸ§° Tech Stack

- Python
- Selenium (for web automation)
- Regular Expressions (`re`)
- `openpyxl` (for Excel output)

## ğŸ“ Project Structure

nextdoor-scraper/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scraper.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ nextdoor_urls.xlsx
â”‚
â”œâ”€â”€ output/
â”‚   â””â”€â”€ nextdoor_data.xlsx

## ğŸš€ How to Run

### 1. Clone the Repository
```bash
git clone https://github.com/okomaga/nextdoor-scraper.git
cd nextdoor-scraper

2. Install Dependencies

pip install -r requirements.txt

Required libraries:
	â€¢	selenium
	â€¢	openpyxl

Also install the correct WebDriver (e.g., ChromeDriver) and make sure itâ€™s in your system PATH.

3. Prepare Input File

Add your 100 Nextdoor URLs into:

data/nextdoor_urls.xlsx

One URL per row.

4. Run the Script

python scraper.py

Scraped data will be saved to:

output/nextdoor_data.xlsx

ğŸ“ Output Columns
	â€¢	Company Name
	â€¢	Email (if found)
	â€¢	Website (if listed)
	â€¢	Source URL

ğŸ“„ License

This project is licensed under the MIT License.
